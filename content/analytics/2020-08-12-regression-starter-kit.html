---
title: Regression Starter Kit
author: Jeff Cavanagh
date: '2020-08-12'
slug: regression-starter-kit
categories:
  - R
tags: []
lastmod: '2020-08-13T05:25:19-04:00'
layout: post
type: post
highlight: yes
---



<p><strong>This post will cover some of the primary methods of regression analysis available in R. It will also serve as a warmup for the posts that explore Machine Learning and its applications.</strong></p>
<div id="setup" class="section level3">
<h3>Setup</h3>
<p>For our regression data we will look at statistics concerning the history of my favorite sports team, The Detroit Lions. The data comes from <a href="https://www.pro-football-reference.com/teams/det/" target="&quot;_blank">Pro Football Reference</a>.</p>
<pre class="r"><code>lions &lt;- read.csv(&quot;sportsref_download - sportsref_download.csv&quot;)

str(lions)</code></pre>
<pre><code>## &#39;data.frame&#39;:    90 obs. of  29 variables:
##  $ Year       : int  2019 2018 2017 2016 2015 2014 2013 2012 2011 2010 ...
##  $ Lg         : Factor w/ 1 level &quot;NFL&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Tm         : Factor w/ 3 levels &quot;Detroit Lions&quot;,..: 1 1 1 2 1 2 1 1 2 1 ...
##  $ W          : int  3 6 9 9 7 11 7 4 10 6 ...
##  $ L          : int  12 10 7 7 9 5 9 12 6 10 ...
##  $ T          : int  1 0 0 0 0 0 0 0 0 0 ...
##  $ Div..Finish: Factor w/ 19 levels &quot;1st of 4&quot;,&quot;1st of 5&quot;,..: 12 12 5 5 9 5 9 12 5 9 ...
##  $ Playoffs   : Factor w/ 6 levels &quot;&quot;,&quot;Lost Champ&quot;,..: 1 1 1 5 1 5 1 1 5 1 ...
##  $ PF         : int  341 324 410 346 358 321 395 372 474 362 ...
##  $ PA         : int  423 360 376 358 400 282 376 437 387 369 ...
##  $ PD         : int  -82 -36 34 -12 -42 39 19 -65 87 -7 ...
##  $ Coaches    : Factor w/ 27 levels &quot;Caldwell&quot;,&quot;Clark&quot;,..: 20 20 1 1 1 1 26 26 26 26 ...
##  $ AV         : Factor w/ 35 levels &quot;&quot;,&quot;Allen&quot;,&quot;Backus&quot;,..: 16 31 31 31 31 34 34 20 31 34 ...
##  $ Passer     : Factor w/ 40 levels &quot;&quot;,&quot;Batch&quot;,&quot;Clark&quot;,..: 37 37 37 37 37 37 37 37 37 11 ...
##  $ Rusher     : Factor w/ 41 levels &quot;&quot;,&quot;Abdullah&quot;,..: 18 18 2 28 2 3 6 21 4 4 ...
##  $ Receiver   : Factor w/ 47 levels &quot;&quot;,&quot;Barr&quot;,&quot;Box&quot;,..: 16 16 25 42 24 42 24 24 24 24 ...
##  $ Pts        : int  18 25 7 20 18 22 13 17 4 15 ...
##  $ Yds        : int  17 24 13 21 20 19 6 3 5 17 ...
##  $ Pts.1      : int  26 16 21 13 23 3 15 27 23 19 ...
##  $ Yds.1      : int  31 10 27 18 18 2 16 13 23 21 ...
##  $ T.G        : int  24 23 5 20 22 6 28 30 4 11 ...
##  $ Pts.       : int  24 21 13 21 18 13 13 23 8 17 ...
##  $ Yds.       : int  28 21 19 24 17 5 5 2 9 20 ...
##  $ out.of     : int  32 32 32 32 32 32 32 32 32 32 ...
##  $ MoV        : num  -5.1 -2.3 2.1 -0.8 -2.6 2.4 1.2 -4.1 5.4 -0.4 ...
##  $ SoS        : num  -0.1 -0.8 0.6 -0.6 2.4 -0.4 -2.8 1.8 0.6 2.3 ...
##  $ SRS        : num  -5.2 -3 2.7 -1.4 -0.2 2.1 -1.6 -2.3 6.1 1.9 ...
##  $ OSRS       : num  -1.2 -3.3 5.2 -1.3 1 -3.2 -1.2 2.1 6.9 2.4 ...
##  $ DSRS       : num  -4 0.3 -2.5 -0.1 -1.3 5.2 -0.5 -4.4 -0.8 -0.5 ...</code></pre>
<p>Before we continue with this data we should clean it up. Luckily all columns are either numeric, integer, or factor in format. This will make them easier to run the regression analysis on.</p>
<p>Some categories are missing section headers that needed to be taken out to read the data easily. Without context, some columns have the same names. We will go in add to these names so they are easier to understand.</p>
<p>Also, this analysis will only consider the Detroit Lions (even though the team was originally names the Portsmouth Spartans). Therefore we will remove the columns of the team’s name and league.</p>
<pre class="r"><code>names(lions)[c(4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24)] &lt;- c(
  &quot;wins&quot;, &quot;loss&quot;, &quot;ties&quot;, &quot;off.pts.rnk&quot;, &quot;off.yds.rnk&quot;, &quot;def.pts.rnk&quot;, 
  &quot;def.yds.rnk&quot;, &quot;tak.giv.rnk&quot;, &quot;pts.df.rnk&quot;, &quot;yds.df.rnk&quot;, &quot;num.teams&quot;
)

names(lions) &lt;- names(lions) %&gt;% str_to_lower()

lions &lt;- lions[, -c(2,3)]</code></pre>
<p>Now we have a clean data frame consisting of 27 variables and 90 rows (representing 90 years of play). We are able to now carry out our analysis.</p>
<div id="simple-linear-regression" class="section level4">
<h4>Simple Linear Regression</h4>
<p>First this data will be put through a simple linear regression model (regression with one predictor variable).</p>
<p><code>lm</code> is a built-in function of R that fits linear models. Applying it to the <code>lions</code> data set let ‘wins’ the response variable (the one we are attempting to predict) and <code>mov</code> (Margin og Victory) as the predictor variable (the one we will base the prediction on).</p>
<pre class="r"><code>slr_model &lt;- lm(wins ~ mov, data = lions)

summary(slr_model)</code></pre>
<pre><code>## 
## Call:
## lm(formula = wins ~ mov, data = lions)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.8672 -1.4241  0.0451  1.0530  4.6514 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  6.44107    0.16472   39.10   &lt;2e-16 ***
## mov          0.32411    0.02516   12.88   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.556 on 88 degrees of freedom
## Multiple R-squared:  0.6534, Adjusted R-squared:  0.6495 
## F-statistic: 165.9 on 1 and 88 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>confint(slr_model)</code></pre>
<pre><code>##                 2.5 %    97.5 %
## (Intercept) 6.1137357 6.7684091
## mov         0.2741033 0.3741208</code></pre>
<p>The <code>summary</code> function gives an overview of the model (coefficients, residuals, levels of significance, etc.) and the <code>confint</code> function gives the confidence interval for each coefficent estimate (default is 95%).</p>
<p>The output gives a simple linear regression model with the formula to predict the wins the Lions will have:</p>
<p><span class="math inline">\(\text{wins } = 6.44107 + 0.32411 * \text{ mov }\)</span></p>
<pre class="r"><code>plot(lions$mov, lions$wins)
abline(slr_model)</code></pre>
<p><img src="/analytics/2020-08-12-regression-starter-kit_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Without going too in depth into the underlying statistical analysis, we can see from the p-values of each coefficient, the F-statistic, and the <span class="math inline">\(R^2\)</span> value that there is a significant relationship between <code>mov</code> and <code>wins</code>. This was expected as I showed that margin of victory is the most significant predictor for the number of wins a team will have in my <a href="/projects/nfl-team-wins-regression-analysis/index.html" target="_blank">2017 NFL Regression Project</a>.</p>
<p>However, this is a very simple model and there are many other variables at our disposal to increase its predictive capability. To take other variables under consideration, we will add them in using a multiple linear regression model.</p>
</div>
<div id="multiple-linear-regression" class="section level4">
<h4>Multiple Linear Regression</h4>
<p>To warm up for a including more variables, we will first only consider non-factor variables. We will also remove the year, loss, tie, and point differential (pd) variables.</p>
<pre class="r"><code>mlr_model &lt;- lm(wins ~ . - year - loss - ties - pd - div..finish - playoffs - coaches - av - passer - rusher - receiver, data = lions)

summary(mlr_model)</code></pre>
<pre><code>## 
## Call:
## lm(formula = wins ~ . - year - loss - ties - pd - div..finish - 
##     playoffs - coaches - av - passer - rusher - receiver, data = lions)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.8608 -0.5767 -0.0945  0.6123  3.2891 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  3.862894   0.638566   6.049 5.48e-08 ***
## pf           0.031060   0.023100   1.345   0.1829    
## pa          -0.026349   0.023052  -1.143   0.2567    
## off.pts.rnk -0.002395   0.095668  -0.025   0.9801    
## off.yds.rnk  0.025639   0.067506   0.380   0.7052    
## def.pts.rnk -0.018651   0.063583  -0.293   0.7701    
## def.yds.rnk  0.018234   0.054323   0.336   0.7381    
## tak.giv.rnk -0.059268   0.034163  -1.735   0.0869 .  
## pts.df.rnk  -0.030496   0.105752  -0.288   0.7739    
## yds.df.rnk   0.004136   0.078556   0.053   0.9582    
## num.teams    0.094658   0.059700   1.586   0.1171    
## mov         -1.297174   3.015030  -0.430   0.6683    
## sos         -1.243980   3.037990  -0.409   0.6834    
## srs         -0.268629   3.657786  -0.073   0.9417    
## osrs         1.441590   3.272233   0.441   0.6608    
## dsrs         1.553113   3.269455   0.475   0.6362    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.297 on 74 degrees of freedom
## Multiple R-squared:  0.7974, Adjusted R-squared:  0.7563 
## F-statistic: 19.41 on 15 and 74 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The <span class="math inline">\(R^2\)</span> value of the model went from 0.65 in the simple model to 0.79 in the multiple model, meaning noticeable improvement.</p>
<p>It is worth noting though that some coefficient p-values are very high. Let’s quickly take out <code>off.pts.rnk</code>, <code>yds.df.rnk</code>, and <code>srs</code> to see if it improves the model further.</p>
<pre class="r"><code>mlr_model &lt;- lm(wins ~ . - year - loss - ties - pd - div..finish - playoffs - coaches - av - passer - rusher - receiver - srs - off.pts.rnk - yds.df.rnk, data = lions)

summary(mlr_model)</code></pre>
<pre><code>## 
## Call:
## lm(formula = wins ~ . - year - loss - ties - pd - div..finish - 
##     playoffs - coaches - av - passer - rusher - receiver - srs - 
##     off.pts.rnk - yds.df.rnk, data = lions)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.8511 -0.5817 -0.1072  0.6169  3.2869 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  3.87220    0.61508   6.295 1.73e-08 ***
## pf           0.03111    0.02200   1.414   0.1613    
## pa          -0.02646    0.02208  -1.199   0.2344    
## off.yds.rnk  0.02803    0.03533   0.793   0.4300    
## def.pts.rnk -0.01848    0.05692  -0.325   0.7463    
## def.yds.rnk  0.02059    0.03477   0.592   0.5554    
## tak.giv.rnk -0.05946    0.03304  -1.800   0.0758 .  
## pts.df.rnk  -0.03091    0.07672  -0.403   0.6882    
## num.teams    0.09358    0.05304   1.764   0.0816 .  
## mov         -1.41885    2.46238  -0.576   0.5662    
## sos         -1.36473    2.48406  -0.549   0.5843    
## osrs         1.29582    2.49017   0.520   0.6043    
## dsrs         1.40464    2.48042   0.566   0.5728    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.272 on 77 degrees of freedom
## Multiple R-squared:  0.7973, Adjusted R-squared:  0.7657 
## F-statistic: 25.24 on 12 and 77 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The model did not change much. Further tinkering with which variables too include would most likely eventually show improvement. We are also able to put in interactive terms and apply various evolutions to the predictor variables (logarithms, polynomial form, etc.). However, we will move on to include some of the qualitative variables.</p>
<p>Some variables, (<code>div..finish</code> and <code>playoffs</code> mainly), are determined strongly by the amount of wins, and as such we will continue to exclude them from the model.</p>
<p>Instead we will focus on the components of the team: the coach, and leading player (<code>av</code>), <code>passer</code>, <code>rusher</code>, and <code>reciever</code>. These factors have many different levels (new players and coaches are constantly introduced over the 90 year history of the team). Therefore we wills start by adding a single variable <code>av</code>.</p>
<pre class="r"><code>mlr_model2 &lt;- lm(wins ~ . - year - loss - ties - pd - div..finish - playoffs - coaches - passer - rusher - receiver - srs - off.pts.rnk - yds.df.rnk, data = lions)

summary(mlr_model2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = wins ~ . - year - loss - ties - pd - div..finish - 
##     playoffs - coaches - passer - rusher - receiver - srs - off.pts.rnk - 
##     yds.df.rnk, data = lions)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.6953 -0.4602  0.0000  0.3679  2.8723 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  5.317316   1.168851   4.549 4.36e-05 ***
## pf           0.003821   0.029136   0.131   0.8963    
## pa          -0.002146   0.028990  -0.074   0.9413    
## avAllen      1.693980   2.140220   0.791   0.4330    
## avBackus     3.228701   2.318178   1.393   0.1708    
## avBaker      1.627634   2.282966   0.713   0.4797    
## avBarney    -0.404525   1.203527  -0.336   0.7384    
## avBly        2.956414   2.647252   1.117   0.2703    
## avBoyd       2.075853   2.477845   0.838   0.4068    
## avBrown     -2.044672   1.398903  -1.462   0.1511    
## avCofer     -0.600716   2.409106  -0.249   0.8043    
## avCrockett   4.157786   2.258704   1.841   0.0726 .  
## avCrowell    1.493016   2.430716   0.614   0.5423    
## avDanielson  3.028294   2.142239   1.414   0.1647    
## avEnglish   -0.953646   2.223656  -0.429   0.6702    
## avFlanagan  -0.593500   1.872505  -0.317   0.7528    
## avFreitas    1.616848   2.100360   0.770   0.4456    
## avGolladay   0.829198   2.543667   0.326   0.7460    
## avGriffin    2.837596   2.249674   1.261   0.2140    
## avHipple     3.446999   2.281158   1.511   0.1381    
## avHunter     2.310857   2.181524   1.059   0.2954    
## avJohnson    1.415249   2.035305   0.695   0.4906    
## avKarras     0.307533   1.297291   0.237   0.8137    
## avKitna      4.179400   2.479530   1.686   0.0991 .  
## avLandry     0.755007   1.943549   0.388   0.6996    
## avLane       1.837680   1.452829   1.265   0.2127    
## avLary       1.998708   1.596830   1.252   0.2175    
## avMoore      1.634796   2.121103   0.771   0.4451    
## avMunson     1.513856   2.048460   0.739   0.4639    
## avRogers     1.665527   2.291293   0.727   0.4712    
## avSanders    2.778367   1.861861   1.492   0.1429    
## avSims       0.588177   1.913874   0.307   0.7601    
## avStafford   2.661468   2.172085   1.225   0.2271    
## avStewart    2.879476   2.566850   1.122   0.2682    
## avStudstill  1.180546   1.514905   0.779   0.4401    
## avSuh        1.242929   2.184177   0.569   0.5723    
## avWalker     0.774449   1.236180   0.626   0.5343    
## off.yds.rnk  0.007376   0.055775   0.132   0.8954    
## def.pts.rnk -0.187049   0.085995  -2.175   0.0352 *  
## def.yds.rnk  0.016785   0.054688   0.307   0.7604    
## tak.giv.rnk -0.060948   0.041545  -1.467   0.1496    
## pts.df.rnk  -0.071550   0.116566  -0.614   0.5426    
## num.teams    0.145084   0.111307   1.303   0.1994    
## mov         -1.686136   3.078606  -0.548   0.5867    
## sos         -1.877817   3.109018  -0.604   0.5490    
## osrs         1.869662   3.112756   0.601   0.5512    
## dsrs         1.832578   3.070287   0.597   0.5537    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.214 on 43 degrees of freedom
## Multiple R-squared:  0.8968, Adjusted R-squared:  0.7864 
## F-statistic: 8.125 on 46 and 43 DF,  p-value: 9.48e-11</code></pre>
<p>Similar to the jump from simple to multiple regression, adding in the <code>av</code> (most valuable team player) categorical variable improved the model, even if not all predictors are significant.</p>
<p>Looking at the estimated coefficent values for each level of the <code>av</code> predictor variable, we can see that some players have a much higher influence on the number of wins when they are the team’s mvp.</p>
<p>Barry Sanders for instance, Hall of Fame running back, has a large positive coefficient estimate (2.78) with a comparatively low p-value. This suggests that when he was the most valuable player on the team, the Lions could expect more wins. This is corroborated by the fact that during the 1991 season (in which Barry Sanders was the <code>av</code> player) the Lions attained their only playoff win in the Super Bowl era.</p>
<p>Now lets run the model one more time with the one additional qualitative predictor factored in (<code>coaches</code>).</p>
<pre class="r"><code>mlr_model3 &lt;- lm(wins ~ . - year - loss - ties - pd - div..finish - playoffs - passer - rusher - receiver - srs - off.pts.rnk - yds.df.rnk, data = lions)

summary(mlr_model3)</code></pre>
<pre><code>## 
## Call:
## lm(formula = wins ~ . - year - loss - ties - pd - div..finish - 
##     playoffs - passer - rusher - receiver - srs - off.pts.rnk - 
##     yds.df.rnk, data = lions)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.7992 -0.2615  0.0000  0.0000  2.1359 
## 
## Coefficients: (7 not defined because of singularities)
##                          Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)             10.887606  16.143493   0.674   0.5065  
## pf                       0.025323   0.044832   0.565   0.5774  
## pa                      -0.014056   0.046414  -0.303   0.7646  
## coachesClark            -4.438381  11.469226  -0.387   0.7022  
## coachesDorais           -5.302329  11.133030  -0.476   0.6382  
## coachesEdwards          -3.587910  11.042299  -0.325   0.7481  
## coachesFontes            2.185460   3.136214   0.697   0.4926  
## coachesForzano           0.449686   4.132438   0.109   0.9143  
## coachesGilmer           -5.493556  10.253150  -0.536   0.5970  
## coachesGriffen          -6.167133  11.009393  -0.560   0.5806  
## coachesHenderson        -3.723253  11.135996  -0.334   0.7410  
## coachesHudspeth         -0.179822   3.409350  -0.053   0.9584  
## coachesHudspeth,Forzano -1.793777   3.869419  -0.464   0.6471  
## coachesKarcis,Edwards   -4.884829  11.124039  -0.439   0.6645  
## coachesMarinelli         2.347548   4.180315   0.562   0.5796  
## coachesMariucci          1.147870   2.349598   0.489   0.6296  
## coachesMariucci,Jauron   1.293237   2.304054   0.561   0.5798  
## coachesMcCafferty       -0.642926   9.743401  -0.066   0.9479  
## coachesMcMillin         -6.125011  10.859969  -0.564   0.5780  
## coachesMornhinweg       -2.302807   3.248728  -0.709   0.4853  
## coachesParker           -4.918252  10.604144  -0.464   0.6470  
## coachesPatricia         -2.981367   1.839050  -1.621   0.1181  
## coachesRogers           -2.365061   4.198306  -0.563   0.5784  
## coachesRogers,Fontes    -1.324861   3.084563  -0.430   0.6714  
## coachesRoss              0.467339   2.339266   0.200   0.8433  
## coachesRoss,Moeller      0.900338   2.125559   0.424   0.6756  
## coachesSchmidt          -2.312517   8.778670  -0.263   0.7945  
## coachesSchwartz         -0.295470   1.708327  -0.173   0.8641  
## coachesWilson           -5.083473  10.276688  -0.495   0.6253  
## avAllen                  3.782708   9.142634   0.414   0.6827  
## avBackus                 5.116050   2.760852   1.853   0.0762 .
## avBaker                  3.072649   9.275818   0.331   0.7433  
## avBarney                -2.245664   2.262212  -0.993   0.3308  
## avBly                    1.943671   2.132463   0.911   0.3711  
## avBoyd                         NA         NA      NA       NA  
## avBrown                 -2.071479   1.895693  -1.093   0.2854  
## avCofer                        NA         NA      NA       NA  
## avCrockett              -0.928889   2.060544  -0.451   0.6562  
## avCrowell                0.252435   2.232572   0.113   0.9109  
## avDanielson              5.947016   9.452822   0.629   0.5352  
## avEnglish                2.378653   9.527469   0.250   0.8050  
## avFlanagan              -1.204948   6.457512  -0.187   0.8535  
## avFreitas                2.624936   5.580175   0.470   0.6423  
## avGolladay               4.460222   3.594525   1.241   0.2267  
## avGriffin                4.026763   3.318423   1.213   0.2368  
## avHipple                 4.458664   3.188817   1.398   0.1748  
## avHunter                       NA         NA      NA       NA  
## avJohnson                0.510689   2.476767   0.206   0.8384  
## avKarras                 0.770445   1.673207   0.460   0.6493  
## avKitna                  2.413990   3.716105   0.650   0.5221  
## avLandry                 0.586409   5.979509   0.098   0.9227  
## avLane                   2.215659   2.137388   1.037   0.3102  
## avLary                   2.157563   2.224733   0.970   0.3418  
## avMoore                 -1.245353   1.675209  -0.743   0.4645  
## avMunson                       NA         NA      NA       NA  
## avRogers                       NA         NA      NA       NA  
## avSanders                      NA         NA      NA       NA  
## avSims                   1.743287   9.354473   0.186   0.8537  
## avStafford               2.273137   1.738783   1.307   0.2035  
## avStewart                5.557224   4.179763   1.330   0.1962  
## avStudstill              3.339718   3.280285   1.018   0.3188  
## avSuh                          NA         NA      NA       NA  
## avWalker                 1.316604   2.159352   0.610   0.5478  
## off.yds.rnk             -0.002237   0.107451  -0.021   0.9836  
## def.pts.rnk             -0.150446   0.125935  -1.195   0.2439  
## def.yds.rnk             -0.143288   0.111328  -1.287   0.2103  
## tak.giv.rnk             -0.094801   0.054108  -1.752   0.0925 .
## pts.df.rnk              -0.016118   0.169586  -0.095   0.9251  
## num.teams               -0.043697   0.535342  -0.082   0.9356  
## mov                     -3.206226   4.052729  -0.791   0.4366  
## sos                     -3.273682   4.131951  -0.792   0.4360  
## osrs                     3.164494   4.088558   0.774   0.4465  
## dsrs                     3.121475   4.021032   0.776   0.4452  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.345 on 24 degrees of freedom
## Multiple R-squared:  0.9294, Adjusted R-squared:  0.7381 
## F-statistic: 4.859 on 65 and 24 DF,  p-value: 3.365e-05</code></pre>
<p>It is worth noting that when <code>coaches</code> are put into the model, the Lions current Head Coach Matt Patricia has a large negative coefficient (-2.98) with a comparitvely low p-value, implicating relative significance. This stands to reason, as looking at the last three years under Patricia’s tenure the Lions record has been 9 - 17 - 1.</p>
<p>When coaches are input, the model continues to improve, however we are started to get some <code>NA</code> values for factor levels. The volume of factors from multiple dummy variables is starting to put too much pressure on the model. This is where multiple regression starts begins to fall short, making it a perfect time to move on to our next approach.</p>
<p>I first learned the techniques showcased in this post from <em>An Introduction to Statistical Learning: with Applications in R</em>.</p>
</div>
</div>
